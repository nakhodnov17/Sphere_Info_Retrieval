{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with io.open('train_data.json','r',encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        d = json.loads(line)\n",
    "        train_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with io.open('test_data.json','r',encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        d = json.loads(line)\n",
    "        test_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "Index = 0\n",
    "train_reform = []\n",
    "for k in range(len(train_data)):\n",
    "    pos = - 1\n",
    "    true_positions = []\n",
    "    for sent in train_data[k][u'Sentences']:\n",
    "        pos += len(sent) \n",
    "        true_positions += [pos]\n",
    "        pos += 1\n",
    "\n",
    "    string = train_data[k]['Paragraph']\n",
    "    Marks = []\n",
    "    positions = []\n",
    "    pos = 0\n",
    "    for i in re.findall(re.compile(u'[!\"…\\.»?]', re.U), string):\n",
    "        pos = string.find(i, pos + 1, len(string))\n",
    "        positions += [pos]\n",
    "    for pos in positions:\n",
    "        Index += 1\n",
    "        if pos in true_positions:\n",
    "            label = True\n",
    "        else:\n",
    "            label = False\n",
    "        Marks += [{u'Index': Index, u'Pos': pos, u'Mark': string[pos], u'Label': label}]\n",
    "    train_reform += [{'Paragraph': string, 'Marks': Marks}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_of_sentences = set()\n",
    "# for paragraph in train_data:\n",
    "#     for sentence in paragraph['Sentences']:\n",
    "#         end_of_sentences.add(sentence[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLabelOneHotEncoder():\n",
    "    def __init__(self):\n",
    "        self.label_enc = LabelEncoder()\n",
    "        self.one_hot_enc = OneHotEncoder()\n",
    "        self.result_len = 0\n",
    "        \n",
    "    def fit(self, array):\n",
    "        self.label_enc.fit(array)\n",
    "        self.one_hot_enc.fit(self.label_enc.transform(array).reshape(-1, 1))\n",
    "        self.result_len = len(array)\n",
    "        \n",
    "    def predict_one(self, label):\n",
    "        return self.one_hot_enc.transform(self.label_enc.transform([label])[0]).toarray()[0]\n",
    "    \n",
    "    def predict_none(self):\n",
    "        return np.zeros(self.result_len, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_sentences = np.array([u'!', u'\"', u'.', u'?', u'\\xbb', u'\\u2026'])\n",
    "end_encoder = MyLabelOneHotEncoder()\n",
    "end_encoder.fit(end_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ends = [u'!', u'…', u'.', u'?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_cand = Counter()\n",
    "for p in train_reform:\n",
    "    par = p['Paragraph']\n",
    "    for cand in p['Marks']:\n",
    "        pos = cand['Pos']\n",
    "        ## _'alpha'._\n",
    "        if (pos >= 3 and pos + 1 < len(par) and\n",
    "            par[pos - 2] == ' ' and par[pos] == '.' and\n",
    "            par[pos - 1].isalpha() and par[pos - 1].islower() and\n",
    "            par[pos + 1] == ' '):\n",
    "            stop_words_cand[par[pos - 1:pos + 1]] += 1\n",
    "        ## _'alpha''alpha'._\n",
    "        if (pos >= 3 and pos + 1 < len(par) and\n",
    "            par[pos - 3] == ' ' and\n",
    "            par[pos - 2].isalpha() and par[pos - 2].islower() and\n",
    "            par[pos - 1].isalpha() and par[pos - 1].islower() and\n",
    "            par[pos] == '.' and par[pos + 1] == ' '):\n",
    "            stop_words_cand[par[pos - 2:pos + 1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "г. 163\n",
      "т. 108\n",
      "ст. 57\n",
      "им. 54\n",
      "см. 40\n",
      "н. 39\n",
      "гг. 31\n",
      "д. 27\n",
      "же. 25\n",
      "км. 24\n",
      "ч. 24\n",
      "м. 22\n",
      "он. 21\n",
      "е. 19\n",
      "мм. 19\n",
      "в. 19\n",
      "др. 18\n",
      "их. 16\n",
      "с. 16\n",
      "э. 14\n",
      "ее. 14\n",
      "кв. 14\n",
      "я. 13\n",
      "бы. 13\n",
      "п. 10\n",
      "пр. 10\n",
      "её. 9\n",
      "кг. 9\n",
      "ул. 9\n",
      "св. 8\n",
      "да. 7\n",
      "m. 7\n",
      "гр. 6\n"
     ]
    }
   ],
   "source": [
    "for word, cnt in stop_words_cand.most_common():\n",
    "    if cnt > 5:\n",
    "        print word, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set([u'им.', u'ст.', u'др.', u'ул.',\n",
    "                  u'вв.', u'см.', u'гг.', u'кв.',\n",
    "                  u'св.', u'км', u'мм.', u'г.',\n",
    "                  u'т.', u'н', u'д', u'ч', \n",
    "                  u'м', u'е', u'в', u'с',\n",
    "                  u'э', u'п'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_encoder = MyLabelOneHotEncoder()\n",
    "stop_encoder.fit(list(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = np.zeros((26476,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_num = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(par, cand):\n",
    "    features = np.zeros([1, 0])\n",
    "    is_eof = False                      # 0\n",
    "    is_next_space = False               # 1\n",
    "    is_next_in_ends = False             # 2\n",
    "    is_next_alpha_upper = False         # 3\n",
    "    is_initial = False                  # 4\n",
    "    is_numerated_list_beg = False       # 5\n",
    "    is_in_good_ends = False             # 6\n",
    "    is_city_or_year = False             # 7\n",
    "    # Сложные правила:\n",
    "    ## ._'digit'._'upper'\n",
    "    is_next_list_begin = False          # 8\n",
    "    # +Нестрогие\n",
    "    ## 'upper'._'upper'\n",
    "    is_feature_9 = False                # 9\n",
    "    ## 'upper''lower'._'upper'\n",
    "    is_feature_10 = False               # 10\n",
    "    is_is_stop_words = False            # 11\n",
    "    \n",
    "    pos = cand['Pos']\n",
    "    \n",
    "    # 0\n",
    "    if pos == len(par) - 1:\n",
    "        is_eof = True\n",
    "    features = np.append(features, is_eof)\n",
    "    # 1\n",
    "    if pos + 1 < len(par) and par[pos + 1] == ' ':\n",
    "        is_next_space = True\n",
    "    features = np.append(features, is_next_space)\n",
    "    # 2\n",
    "    if pos + 2 < len(par) and par[pos + 2].isalpha() and par[pos +2].isupper():\n",
    "        is_next_alpha_upper = True\n",
    "    features = np.append(features, is_next_alpha_upper)\n",
    "    # 3\n",
    "    if pos + 1 < len(par) and par[pos + 1] in end_of_sentences:\n",
    "        is_next_in_ends = True\n",
    "    features = np.append(features, is_next_in_ends)\n",
    "    # 4\n",
    "    if pos >= 2 and par[pos] == '.' and par[pos - 2] == '.' and par[pos - 1].isalpha() and par[pos - 1].isupper():\n",
    "        is_initial = True\n",
    "    features = np.append(features, is_initial)\n",
    "    # 5\n",
    "    if pos >= 1 and par[pos] == '.' and par[pos - 1].isdigit():\n",
    "        is_numerated_list_beg = True\n",
    "    features = np.append(features, is_numerated_list_beg)\n",
    "    # 6\n",
    "    if cand['Mark'] in good_ends:\n",
    "        is_in_good_ends = True\n",
    "    features = np.append(features, is_in_good_ends)\n",
    "    # 7\n",
    "    if pos >= 1 and pos + 1 < len(par) and par[pos - 1:pos + 2] == u'г. ':\n",
    "        is_city_or_year = True\n",
    "    features = np.append(features, is_city_or_year)\n",
    "    # 8\n",
    "    ## ._d._A\n",
    "    ## ._dd._A\n",
    "    ## ._d.A\n",
    "    ## ._dd.A\n",
    "    if (pos + 5 < len(par) and \n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos + 2].isdigit() and\n",
    "        par[pos + 3] == '.' and par[pos + 4] == ' ' and\n",
    "        par[pos + 5].isalpha() and par[pos + 5].isupper()):\n",
    "        is_next_list_begin = True\n",
    "    if (pos + 6 < len(par) and \n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos + 2].isdigit() and\n",
    "        par[pos + 3].isdigit() and\n",
    "        par[pos + 4] == '.' and par[pos + 5] == ' ' and\n",
    "        par[pos + 6].isalpha() and par[pos + 6].isupper()):\n",
    "        is_next_list_begin = True\n",
    "    if (pos + 4 < len(par) and \n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos + 2].isdigit() and\n",
    "        par[pos + 3] == '.' and\n",
    "        par[pos + 4].isalpha() and par[pos + 4].isupper()):\n",
    "        is_next_list_begin = True\n",
    "    if (pos + 5 < len(par) and \n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos + 2].isdigit() and\n",
    "        par[pos + 3].isdigit() and\n",
    "        par[pos + 4] == '.' and\n",
    "        par[pos + 5].isalpha() and par[pos + 5].isupper()):\n",
    "        is_next_list_begin = True\n",
    "    features = np.append(features, is_next_list_begin)\n",
    "    # 9\n",
    "    if (pos >= 1 and pos + 2 < len(par) and\n",
    "        par[pos - 1].isalpha() and par[pos - 1].isupper() and\n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos + 2].isalpha() and par[pos + 2].isupper()):\n",
    "        is_feature_9 = True\n",
    "    features = np.append(features, is_feature_9)\n",
    "    # 10\n",
    "    if (pos >= 2 and pos + 2 < len(par) and\n",
    "        par[pos - 2].isalpha() and par[pos - 2].isupper() and\n",
    "        par[pos - 1].isalpha() and par[pos - 1].islower() and\n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos + 2].isalpha() and par[pos + 2].isupper()):\n",
    "        is_feature_10 = True  \n",
    "    features = np.append(features, is_feature_10)\n",
    "    # 11\n",
    "    if (pos >= 3 and pos + 1 < len(par) and\n",
    "        par[pos - 3] == ' ' and\n",
    "        par[pos - 2].isalpha() and par[pos - 2].islower() and\n",
    "        par[pos - 1].isalpha() and par[pos - 1].islower() and\n",
    "        par[pos] == '.' and par[pos + 1] == ' ' and\n",
    "        par[pos - 2:pos + 1] in stop_words):\n",
    "        is_is_stop_words = True\n",
    "        features = np.append(features, stop_encoder.predict_one(par[pos - 2:pos + 1]))\n",
    "    else:\n",
    "        features = np.append(features, stop_encoder.predict_none())\n",
    "\n",
    "    # append type of mark\n",
    "    features = np.append(features, end_encoder.predict_one(par[pos]))\n",
    "    \n",
    "#     if is_eof:\n",
    "#         return 1, features\n",
    "    \n",
    "#     if is_initial:\n",
    "#         return 0, features\n",
    "    \n",
    "#     if is_city_or_year:\n",
    "#         return 0, features\n",
    "        \n",
    "#     if is_next_in_ends:\n",
    "#         return 0, features\n",
    "    \n",
    "#     if is_numerated_list_beg:\n",
    "#         return 0, features\n",
    "    \n",
    "#     if is_next_list_begin:\n",
    "#         return 1, features\n",
    "\n",
    "#     if not is_in_good_ends:\n",
    "#         return 0, features\n",
    "    \n",
    "#     if is_in_good_ends and (is_next_space and is_next_alpha_upper):\n",
    "#         return 1, features\n",
    "            \n",
    "    return 0, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros([0, fea_num])\n",
    "y = np.zeros([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-683f471c0194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Marks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-3cb3c5119957>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(par, cand)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# append type of mark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m#     if is_eof:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f2bc7ee2da0e>\u001b[0m in \u001b[0;36mpredict_one\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \"\"\"\n\u001b[1;32m   2074\u001b[0m         return _transform_selected(X, self._transform,\n\u001b[0;32m-> 2075\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2055\u001b[0m         if (isinstance(self.n_values, six.string_types) and\n\u001b[1;32m   2056\u001b[0m                 self.n_values == 'auto'):\n\u001b[0;32m-> 2057\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_features_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# [1:2,??]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             if ((isintlike(col) and row.step in (1, None)) or\n\u001b[0m\u001b[1;32m    300\u001b[0m                     (isinstance(col, slice) and\n\u001b[1;32m    301\u001b[0m                      \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/sputils.pyc\u001b[0m in \u001b[0;36misintlike\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[0msafely\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/sparse/sputils.pyc\u001b[0m in \u001b[0;36misscalarlike\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;34m\"\"\"Is x either a scalar, an array scalar, or a 0-dim array?\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36misscalar\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m   1952\u001b[0m     return (isinstance(num, generic)\n\u001b[1;32m   1953\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mScalarType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m             or isinstance(num, numbers.Number))\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/abc.pyc\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Inline the cache checking when it's simple.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0msubclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__class__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in train_reform:\n",
    "    par = p['Paragraph']\n",
    "    for cand in p['Marks']:\n",
    "        _, features = predict(par, cand)\n",
    "        X = np.append(X, features.reshape(1, -1), axis=0)\n",
    "        y = np.append(y, cand['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = RandomForestClassifier(n_estimators=1000)\n",
    "model = XGBClassifier(n_estimators=2000, base_score=0.5, reg_lambda = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=2000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9429339640404385"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = np.zeros([0, fea_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in test_data:\n",
    "    par = p['Paragraph']\n",
    "    for cand in p['Marks']:\n",
    "        out_data[cand['Index']-1], features = predict(par, cand)\n",
    "        X_real = np.append(X_real, features.reshape(1, -1), axis=0)\n",
    "        pos = cand['Pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_real = model.predict(X_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17533.0 (26476,)\n"
     ]
    }
   ],
   "source": [
    "print np.sum(y_real), y_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fd = open('marks.txt', 'w')\n",
    "for p in test_data:\n",
    "    par = p['Paragraph']\n",
    "    fd.write(par.encode('utf-8') + '\\n')\n",
    "    for cand in p['Marks']:\n",
    "        out_data[cand['Index']-1] = y_real[idx]\n",
    "        pos = cand['Pos']\n",
    "        fd.write(par[max(0,pos-15):pos].encode('utf-8') + '!' + par[pos:min(len(par),pos+15)].encode('utf-8') + ' ' + str(out_data[cand['Index']-1][0]) + '\\n')\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(out_data, columns=['Mark'], index=range(1,26477))\n",
    "df.index.name = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Адвокаты не допущены к задержанным. ovdinfo.org внимательно следит за развитием событий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = u'и Центр им. Вс. Мейерхольда (Москва) объявляют о начале'\n",
    "par = u'Адвокаты не допущены к задержанным. ovdinfo.org внимательно следит за развитием событий.'\n",
    "print par[87]\n",
    "cand = {'Pos' : 87, 'Mark' : '.'}\n",
    "_, fea = predict(par, cand)\n",
    "print fea.reshape(1, -1)\n",
    "model.predict(fea.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Великий режиссер советского кинематографа, мыслитель, новатор и педагог М. Ромм писал о телевидении\n",
    "и Центр им. Вс. Мейерхольда (Москва) объявляют о начале"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
